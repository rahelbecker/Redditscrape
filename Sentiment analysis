setwd("C:/Users/Daniel/Mein Zeug/UNI/2. Semester Mannheim FSS 16/Big Data/Reddit/Analysis/Dta pure")
#source("C:/Users/Daniel/Mein Zeug/UNI/Arbeit/EPL FSQCA/Code/Utilities.R")
#setwd("C:/Users/Daniel/SkyDrive/Mein Zeug/UNI/2. Semester Mannheim FSS 16/Big Data/Reddit/Analysis/Dta pure")
#setwd("L:/HIWIs/2h Daniel/BigData/Dta pure")

library(stringr)
library(tm)
library(dplyr)
library(plyr)

positives= readLines("positive.words.txt")
negatives = readLines("negative.words.txt")

rr_u<-readRDS("rr_u_070515.rds")
sa1prep<-as.data.frame(rr_u[,"selftext"])

sa1<-VCorpus(DataframeSource(sa1prep))

lapply(sa1[1:2],meta)

#assign unique identifier to the texts
changemeta<-function(ss1,ss12){

  for(i in seq(ss1)){
    meta(ss1[[i]],"id")<-ss12[i,"id"]
  }
  return(ss1)
}

#myDebug(changemeta)
sa1<-changemeta(sa1,rr_u)




# Text prep ---------------------------------------------------------------
#remove special characters

#Stopwords to eliminate =

rm_specialchar <- function(dta) {
  for (j in seq(dta))
  {
    dta[[j]]$content <- gsub("/", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("\\|", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("([\\])", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("([\\\"])", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("\n", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("\n\n", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("\n\n&amp;nbsp;\n\n", " ", dta[[j]]$content)
    #dta[[j]]$content <- gsub(",", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("'", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub("nbsp", " ", dta[[j]]$content)
    dta[[j]]$content <- gsub( "[^[:alnum:]]", " ", dta[[j]]$content)
  }
  return(dta)
}

sa1<-rm_specialchar(sa1)

#removing Punctuation
sa1<-tm_map(sa1,removePunctuation)

#removing numbers
sa1<-tm_map(sa1,removeNumbers)

#converting to lowercase
sa1<-tm_map(sa1,content_transformer(tolower))

sa1<-tm_map(sa1,stripWhitespace)

# #tokenization
# sa1<-tm_map(sa1,content_transformer(MC_tokenizer))


ss2<-tm_map(sa1,content_transformer(WordTokenizer))
#lapply(sa1[10:100],as.character)
#lapply(ss2[10:100],as.character)
sa1[[1]]
as.character(sa1[[1]])

ss3<-dataframe<-data.frame(text=unlist(sapply(sa1, `[`, "content")), stringsAsFactors=F)
rownames(ss3)<-gsub(".content","",rownames(ss3))

saveRDS(ss3,"ss3.RDS")

sscores<-function(dta,positive_words,negative_words){
  word_list=str_split(dta,"\\s+")
  words=unlist(word_list)
  positive.matches<-match(words,positive_words)
  negative.matches<-match(words,negative_words)

  positive_matches<-!is.na(positive.matches)
  negative_matches<-!is.na(negative.matches)

  score<- sum(positive_matches)-sum(negative_matches)
  results<-c(sent.score=score,positives=sum(positive_matches),negatives=sum(negative_matches))
  return(results)
}

#sscores(ss3[1,],positives,negatives)

x<-as.data.frame(t(apply(ss3,1,sscores,positive_words=positives,negative_words=negatives)))
x$id<-(row.names(x))
rr_u<-merge(rr_u,x,by = "id")


saveRDS(rr_u,"rr_u_070515.rds")
